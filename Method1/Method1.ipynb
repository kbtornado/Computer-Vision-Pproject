{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T18:34:40.682523499Z",
     "start_time": "2024-03-25T18:34:40.637472349Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T18:34:52.474403740Z",
     "start_time": "2024-03-25T18:34:52.472150501Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    equalized = cv2.equalizeHist(blurred)\n",
    "    return equalized\n",
    "\n",
    "def extract_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def feature_matching(descriptors1, descriptors2):\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = [m for m, n in matches if m.distance < 0.7*n.distance]\n",
    "    return good_matches\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T18:35:38.009289939Z",
     "start_time": "2024-03-25T18:35:37.965545850Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_images_with_labels(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    for subfolder in os.listdir(folder):\n",
    "        full_path = os.path.join(folder, subfolder)\n",
    "        if os.path.isdir(full_path):\n",
    "            for filename in os.listdir(full_path):\n",
    "                img = cv2.imread(os.path.join(full_path, filename))\n",
    "                if img is not None:\n",
    "                    if count % 100 == 0:\n",
    "                        print(\"Loaded img amount:\",count)\n",
    "                    images.append(img)\n",
    "                    labels.append(subfolder)  # The subfolder name is used as the label\n",
    "                    count = count + 1\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Other functions (preprocess_image, extract_features, feature_matching) remain the same\n",
    "\n",
    "def classify_tumor_dataset1(test_image, all_train_folders):\n",
    "    print(\"Classify tumor started\")\n",
    "    preprocessed_test_image = preprocess_image(test_image)\n",
    "    _, test_descriptors = extract_features(preprocessed_test_image)\n",
    "    max_matches = 0\n",
    "    tumor_type = None\n",
    "\n",
    "    for i, images_in_folder in enumerate(all_train_folders):\n",
    "        total_matches = 0\n",
    "        for train_image in images_in_folder:\n",
    "            preprocessed_train_image = preprocess_image(train_image)\n",
    "            _, train_descriptors = extract_features(preprocessed_train_image)\n",
    "            matches = feature_matching(test_descriptors, train_descriptors)\n",
    "            total_matches += len(matches)\n",
    "\n",
    "        avg_matches = total_matches / len(images_in_folder)\n",
    "        if avg_matches > max_matches:\n",
    "            max_matches = avg_matches\n",
    "            if i == 0:\n",
    "                tumor_type = \"meningioma_tumor\"\n",
    "            elif i == 1:\n",
    "                tumor_type = \"glioma_tumor\"\n",
    "            elif i == 2:\n",
    "                tumor_type = \"no_tumor\"\n",
    "            elif i == 3:\n",
    "                tumor_type = \"pituitary_tumor\"\n",
    "\n",
    "    print(\"Classify tumor ended\")\n",
    "    return tumor_type\n",
    "\n",
    "def calculate_accuracy_parallel(test_images, test_labels, all_train_images, num_processes=None):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy in parallel.\n",
    "    :param test_images: List of test images.\n",
    "    :param test_labels: Corresponding labels for the test images.\n",
    "    :param all_train_images: Preloaded training images for classification comparison.\n",
    "    :param num_processes: Number of processes to use. Defaults to None, which means using os.cpu_count() processes.\n",
    "    :return: Accuracy as a float.\n",
    "    \"\"\"\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "\n",
    "        # Map the worker function across all test image and label pairs\n",
    "        predicted_labels = pool.starmap(classify_tumor_dataset1, [(test_image, all_train_images) for test_image in test_images])\n",
    "        #correct_predictions = pool.starmap(classify_tumor, [(test_images, all_train_images)])\n",
    "\n",
    "        correct_predictions = 0\n",
    "        for i, predicted_label in enumerate(predicted_labels):\n",
    "            if predicted_label == test_labels[i]:\n",
    "                correct_predictions += 1\n",
    "\n",
    "        accuracy = correct_predictions / len(test_images)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "train_base_folder = r'/home/tm216/Desktop/mehmet/Method1/dataset1/Training'\n",
    "train_folders = [os.path.join(train_base_folder, f) for f in ['meningioma_tumor', 'glioma_tumor', 'no_tumor', 'pituitary_tumor']]\n",
    "\n",
    "meningioma_images = load_images_from_folder(train_folders[0])\n",
    "glioma_images = load_images_from_folder(train_folders[1])\n",
    "no_tumor_images = load_images_from_folder(train_folders[2])\n",
    "pituitary_images = load_images_from_folder(train_folders[3])\n",
    "\n",
    "all_train_images = [meningioma_images, glioma_images, no_tumor_images, pituitary_images]\n",
    "\n",
    "\n",
    "test_folder = r'/home/tm216/Desktop/mehmet/Method1/dataset1/Testing'\n",
    "\n",
    "test_images, test_labels = load_images_with_labels(test_folder)\n",
    "test_images_subset = test_images[:30] + test_images[130:160] + test_images[250:290]\n",
    "test_labels_subset = test_labels[:30] + test_labels[130:160] + test_labels[250:290]\n",
    "#accuracy = calculate_accuracy(test_images, test_labels, all_train_images)\n",
    "\n",
    "accuracy1 = calculate_accuracy_parallel(test_images_subset[:3], test_labels_subset[:3], all_train_images, num_processes=32)\n",
    "print(\"Accuracy:\", accuracy1)\n",
    "print(f\"Accuracy: {accuracy1 * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Other data\n",
    "Defining functions and running the analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T18:34:45.105467524Z",
     "start_time": "2024-03-25T18:34:45.093258575Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_tumor_dataset2(test_image, all_train_folders):\n",
    "    print(\"Classify tumor started\")\n",
    "    preprocessed_test_image = preprocess_image(test_image)\n",
    "    _, test_descriptors = extract_features(preprocessed_test_image)\n",
    "    max_matches = 0\n",
    "    tumor_type = None\n",
    "\n",
    "    for i, images_in_folder in enumerate(all_train_folders):\n",
    "        total_matches = 0\n",
    "        for train_image in images_in_folder:\n",
    "            preprocessed_train_image = preprocess_image(train_image)\n",
    "            _, train_descriptors = extract_features(preprocessed_train_image)\n",
    "            matches = feature_matching(test_descriptors, train_descriptors)\n",
    "            total_matches += len(matches)\n",
    "\n",
    "        avg_matches = total_matches / len(images_in_folder)\n",
    "        if avg_matches > max_matches:\n",
    "            max_matches = avg_matches\n",
    "            if i == 0:\n",
    "                tumor_type = \"meningioma_tumor\"\n",
    "            elif i == 1:\n",
    "                tumor_type = \"glioma_tumor\"\n",
    "            elif i == 2:\n",
    "                tumor_type = \"no_tumor\"\n",
    "            elif i == 3:\n",
    "                tumor_type = \"pituitary_tumor\"\n",
    "\n",
    "    print(\"Classify tumor ended\")\n",
    "    return tumor_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-25T18:38:26.076586594Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded img amount: 0\n",
      "Loaded img amount: 100\n",
      "Loaded img amount: 200\n",
      "Loaded img amount: 300\n",
      "Loaded img amount: 400\n",
      "Loaded img amount: 500\n",
      "Loaded img amount: 600\n",
      "Loaded img amount: 700\n",
      "Loaded img amount: 800\n",
      "Loaded img amount: 900\n",
      "Loaded img amount: 1000\n",
      "Loaded img amount: 1100\n",
      "Loaded img amount: 1200\n",
      "Loaded img amount: 1300\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n",
      "Classify tumor ended\n",
      "Classify tumor started\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy_parallel2(test_images, test_labels, all_train_images, num_processes=None):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy in parallel.\n",
    "    :param test_images: List of test images.\n",
    "    :param test_labels: Corresponding labels for the test images.\n",
    "    :param all_train_images: Preloaded training images for classification comparison.\n",
    "    :param num_processes: Number of processes to use. Defaults to None, which means using os.cpu_count() processes.\n",
    "    :return: Accuracy as a float.\n",
    "    \"\"\"\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "\n",
    "        # Map the worker function across all test image and label pairs\n",
    "        predicted_labels = pool.starmap(classify_tumor_dataset2, [(test_image, all_train_images) for test_image in test_images])\n",
    "        #correct_predictions = pool.starmap(classify_tumor, [(test_images, all_train_images)])\n",
    "\n",
    "        correct_predictions = 0\n",
    "        for i, predicted_label in enumerate(predicted_labels):\n",
    "            if predicted_label == test_labels[i]:\n",
    "                correct_predictions += 1\n",
    "\n",
    "        accuracy = correct_predictions / len(test_images)\n",
    "\n",
    "    return accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_folder_2 = r'/home/tm216/Desktop/mehmet/Method1/dataset2/archive (5)/Training'\n",
    "test_folder_2 = r'/home/tm216/Desktop/mehmet/Method1/dataset2/archive (5)/Testing'\n",
    "\n",
    "\n",
    "# İkinci dataset için test yapma ve accuracy hesaplama\n",
    "train_folders_2 = [os.path.join(train_folder_2, f) for f in ['meningioma_tumor', 'glioma_tumor', 'no_tumor', 'pituitary_tumor']]\n",
    "\n",
    "\n",
    "meningioma_images2 = load_images_from_folder(train_folders_2[0])\n",
    "glioma_images2 = load_images_from_folder(train_folders_2[1])\n",
    "no_tumor_images2 = load_images_from_folder(train_folders_2[2])\n",
    "pituitary_images2 = load_images_from_folder(train_folders_2[3])\n",
    "\n",
    "all_train_images_2 = [meningioma_images2, glioma_images2, no_tumor_images2, pituitary_images2]\n",
    "\n",
    "\n",
    "test_images_2, test_labels_2 = load_images_with_labels(test_folder_2)\n",
    "test_images_2_subset = test_images_2[:50] +  test_images_2[350:400] + test_images_2[650:500] +  test_images_2[-50:]\n",
    "test_labels_2_subset = test_labels_2[:50] +  test_labels_2[350:400] + test_labels_2[650:500] +  test_labels_2[-50:]\n",
    "\n",
    "\n",
    "accuracy2 = calculate_accuracy_parallel2(test_images_2_subset, test_labels_2_subset, all_train_images_2, num_processes=32)\n",
    "\n",
    "print(\"Accuracy of the second data:\", accuracy2)\n",
    "\n",
    "# Accuracy farkını yazdırma\n",
    "print(f\"First dataset accuracy: {accuracy1 * 100}%\")\n",
    "print(f\"Second dataset accuracy: {accuracy2 * 100}%\")\n",
    "print(f\"Accuracy difference: {abs(accuracy1 - accuracy2) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy değerlerini görselleştirme\n",
    "datasets = ['Dataset 1', 'Dataset 2']\n",
    "accuracies = [accuracy1 * 100, accuracy2 * 100]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=datasets, y=accuracies)\n",
    "plt.title('Dataset Accuracies')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T17:56:50.676405984Z",
     "start_time": "2024-03-25T17:56:50.673965370Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "datasets = ['Dataset 1', 'Dataset 2']\n",
    "accuracies = [accuracy1 * 100, accuracy2 * 100]  # Ensure accuracy1 and accuracy2 are defined\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=datasets, y=accuracies)\n",
    "\n",
    "# Adding the text on top of the bars\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(i, acc + 0.05, f'{acc:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Dataset Accuracies')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "\n",
    "# Adjust y-axis to zoom in more on the accuracies, assuming accuracies are close to each other\n",
    "min_acc = min(accuracies)\n",
    "max_acc = max(accuracies)\n",
    "padding = (max_acc - min_acc) * 0.1  # Add a small padding to ensure the bars don't touch the axis limits\n",
    "plt.ylim(min_acc - padding, max_acc + padding)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
